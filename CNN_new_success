import numpy as np
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt

def noisy_gaussian(x, y, z, SNR, mu_x, mu_y, mu_z, sigma_x, sigma_y, sigma_z,A,B,C):
  f = np.exp(-((x - mu_x) ** 2 / (2 * sigma_x ** 2) + (y - mu_y) ** 2 / (2 * sigma_y ** 2)+ (z - mu_z) ** 2 / (2 * sigma_z ** 2)))
  noisy_f =  A * f + A * np.random.normal(0, (1/SNR), f.shape) 
  return noisy_f

'''
num_samples: number of samples
num_points: number of points in each samples
    [lower_snr,higher_snr]: range of SNR of each samples
center: detect center
input_snr, input_location: for the 4 last experiments, use same snr and location as first generation
'''
def generate_dataset(num_samples,num_points,lower_snr,higher_snr):
    X = np.zeros((num_samples, num_points))
    y = np.zeros((num_samples, 3))
    array_A=[]
    array_B=[]
    snr=[]
    for i in range(num_samples):
        A=np.random.randint(3000, 493000)
        B=np.random.randint(300,7000)
        C=B
        
        #SNR = np.random.uniform(lower_snr, higher_snr)
        SNR = abs(np.random.normal(0, std_dev))

        #maximum location
        mu_x = np.random.uniform(-1, 1)
        mu_y = np.random.uniform(-1, 1)
        mu_z = np.random.uniform(-1, 1)
        
        #sigma_x = np.random.uniform(0.5, 2)
        #sigma_y = np.random.uniform(0.5, 2)
        #sigma_z = np.random.uniform(0.5, 2)
        sigma_x,sigma_y,sigma_z=1,1,1

        points_per_dim = int(np.ceil(num_points**(1/3.)))

        dx = np.linspace(-1, 1, points_per_dim)
        dy = np.linspace(-1, 1, points_per_dim)
        dz = np.linspace(-1, 1, points_per_dim)

        xx, yy, zz = np.meshgrid(dx, dy, dz)
        points = np.column_stack([xx.ravel(), yy.ravel(), zz.ravel()])[:num_points]

        values=[]
        values = noisy_gaussian(points[:,0], points[:,1], points[:,2], SNR, mu_x, mu_y, mu_z, sigma_x, sigma_y, sigma_z,A,B,C)
        max_value=max(values)
        normalized_values = [x / max_value for x in values]
        X[i] = np.array(normalized_values).T
        y[i] = np.array([mu_x, mu_y, mu_z])
        
        #save
        array_A.append(A)
        array_B.append(B)
        snr.append(SNR)
    return np.array(X), np.array(y), np.array(snr), array_A, array_B

def generate_dataset_pro(num_samples,num_points,lower_snr,higher_snr):
    X = np.zeros((num_samples, num_points))
    y = np.zeros((num_samples, 3))
    array_A=[]
    array_B=[]
    snr=[]
    for i in range(num_samples):
        A=np.random.randint(3000, 493000)
        B=np.random.randint(300,7000)
        C=B
        
        SNR = np.random.uniform(lower_snr, higher_snr)
        #SNR = abs(np.random.normal(0, std_dev))

        #maximum location
        mu_x = np.random.uniform(-1, 1)
        mu_y = np.random.uniform(-1, 1)
        mu_z = np.random.uniform(-1, 1)
        
        #sigma_x = np.random.uniform(0.5, 2)
        #sigma_y = np.random.uniform(0.5, 2)
        #sigma_z = np.random.uniform(0.5, 2)
        sigma_x,sigma_y,sigma_z=1,1,1

        points_per_dim = int(np.ceil(num_points**(1/3.)))

        dx = np.linspace(-1, 1, points_per_dim)
        dy = np.linspace(-1, 1, points_per_dim)
        dz = np.linspace(-1, 1, points_per_dim)

        xx, yy, zz = np.meshgrid(dx, dy, dz)
        points = np.column_stack([xx.ravel(), yy.ravel(), zz.ravel()])[:num_points]

        values=[]
        values = noisy_gaussian(points[:,0], points[:,1], points[:,2], SNR, mu_x, mu_y, mu_z, sigma_x, sigma_y, sigma_z,A,B,C)
        max_value=max(values)
        normalized_values = [x / max_value for x in values]
        X[i] = np.array(normalized_values).T
        y[i] = np.array([mu_x, mu_y, mu_z])
        
        #save
        array_A.append(A)
        array_B.append(B)
        snr.append(SNR)
    return np.array(X), np.array(y), np.array(snr), array_A, array_B

def generate_dataset_with_set_snr(num_samples,num_points,snr):
    X = np.zeros((num_samples, num_points))
    y = np.zeros((num_samples, 3))

    for i in range(num_samples):
        A=np.random.randint(3000, 493000)
        B=np.random.randint(300,7000)
        C=B
        
        SNR = snr

        #maximum location
        mu_x = np.random.uniform(-1, 1)
        mu_y = np.random.uniform(-1, 1)
        mu_z = np.random.uniform(-1, 1)
        
        sigma_x,sigma_y,sigma_z=1,1,1

        points_per_dim = int(np.ceil(num_points**(1/3.)))

        dx = np.linspace(-1, 1, points_per_dim)
        dy = np.linspace(-1, 1, points_per_dim)
        dz = np.linspace(-1, 1, points_per_dim)

        xx, yy, zz = np.meshgrid(dx, dy, dz)
        points = np.column_stack([xx.ravel(), yy.ravel(), zz.ravel()])[:num_points]

        values=[]
        values = noisy_gaussian(points[:,0], points[:,1], points[:,2], SNR, mu_x, mu_y, mu_z, sigma_x, sigma_y, sigma_z,A,B,C)
        max_value=max(values)
        normalized_values = [x / max_value for x in values]
        X[i] = np.array(normalized_values).T
        y[i] = np.array([mu_x, mu_y, mu_z])
        
    return np.array(X), np.array(y)


########################################################################################
num_samples=100000
num_points=200
lower_snr=1
higher_snr=100
std_dev = 35
measurements=200
num_test=10000
########################################################################################

# Generate the dataset
X_train, y_train,snr_train,array_A_train,array_B_train = generate_dataset(num_samples,num_points,lower_snr,higher_snr)

# Reshape the input data to match the expected input shape of the model
X_train_input = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)

# Define the input shape
input_shape = (num_points, 1)

# Define the model architecture
model = models.Sequential()

# Add the convolutional layers
model.add(layers.Conv1D(filters=32, kernel_size=3, activation='linear', input_shape=input_shape))
model.add(layers.MaxPooling1D(pool_size=2))
model.add(layers.Conv1D(filters=64, kernel_size=3, activation='relu'))
model.add(layers.MaxPooling1D(pool_size=2))
model.add(layers.Conv1D(filters=128, kernel_size=3, activation='relu'))
model.add(layers.MaxPooling1D(pool_size=2))
model.add(layers.Conv1D(filters=256, kernel_size=3, activation='relu'))
model.add(layers.MaxPooling1D(pool_size=2))
model.add(layers.Conv1D(filters=512, kernel_size=3, activation='relu'))
model.add(layers.MaxPooling1D(pool_size=2))
model.add(layers.Conv1D(filters=1024, kernel_size=3, activation='relu'))
model.add(layers.MaxPooling1D(pool_size=2))

# Flatten the output of the convolutional layers
model.add(layers.Flatten())

# Add the dense layers with dropout
model.add(layers.Dense(512, activation='linear'))
#model.add(layers.Dropout(0.5))
model.add(layers.Dense(256, activation='linear'))
#model.add(layers.Dropout(0.5))
model.add(layers.Dense(128, activation='linear'))
#model.add(layers.Dropout(0.5))
model.add(layers.Dense(3, activation='linear'))

# Compile the model
model.compile(optimizer='Adam', loss='MSE', metrics=['mean_absolute_error'])

#fit the model
model.fit(X_train_input, y_train, epochs=10)

#save the model
model.save('my_model.h5')

#how to load model?
#from keras.models import load_model
#model = load_model('my_model.h5')

def mask(x, num_points_to_add):
    masked=[]
    for i in range(len(x)):
        masked.append(0)
    selected_indices=[]
    for j in range(num_points_to_add):
        selected_indices.append(int(j/num_points_to_add*len(x)))

    for j in range(len(selected_indices)):
        masked[selected_indices[j]] = x[ selected_indices[j]]

    return masked

def draw_pro_snr():   
    lower_snr=1
    higher_snr=100
    X_test, y_test, snr, array_A, array_B = generate_dataset_pro(num_test, num_points, lower_snr, higher_snr)
    step = 10
    total_steps = int(num_points / step)

    success_rates = []
    for i in range(num_test):
        success_count = 0
        entered_sphere = False
        for j in range(total_steps):
            masked_data = mask(X_test[i], (j+1) * step)
            y_pred = model.predict(np.array([masked_data]))

            distance = np.sqrt((y_pred[0][0] - y_test[i][0])**2 + (y_pred[0][1] - y_test[i][1])**2 + (y_pred[0][2] - y_test[i][2])**2)
            if distance < 0.225:
                success_count += 1
                entered_sphere = True
            elif entered_sphere:
                break

        success_rate = success_count / total_steps
        success_rates.append(success_rate)

    x_snr = []
    y_pro = []
    total_number = []
    num_parts = 50
    for i in range(num_parts):
        x_snr.append(lower_snr + (higher_snr - lower_snr) * i / (num_parts - 1))
        y_pro.append(0)
        total_number.append(0)

    for i in range(len(success_rates)):
        tem_snr = min(x_snr, key=lambda x: abs(x - snr[i]))
        total_number[int((tem_snr - lower_snr) / ((higher_snr - lower_snr) / (num_parts - 1)))] += 1
        if success_rates[i] >= 0.5:
            y_pro[int((tem_snr - lower_snr) / ((higher_snr - lower_snr) / (num_parts - 1)))] += 1

    for i in range(num_parts):
        if total_number[i] == 0:
            continue
        y_pro[i] = y_pro[i] / total_number[i]

    print('Success rates:', success_rates)
    print('Discrete SNR:', x_snr)
    print('#success in each SNR:', y_pro)
    print('#total examples in each SNR:', total_number)
    print('#############################################################################')

    plt.plot(x_snr, y_pro)
    plt.xlabel('discrete snr')
    plt.ylabel('pro of success')
    plt.title('Success Probability vs SNR')
    plt.show()




def draw_meas_snr():
    x_snr = list(range(5, 100, 10))
    #x_snr=[100]
    y=[]
    X_mask=[]
    signal=0
    num_test=100
    for snr in x_snr:
        X_test,y_test=generate_dataset_with_set_snr(num_test,num_points,snr)
        success=0
        X_mask=[]
        step=10
        total=int(200/step)
        for i in range(len(X_test)):
            for j in range(1,num_points,step):
                masked=mask(X_test[i],j)
                signal+=1
                X_mask.append(masked)
        y_pred=model.predict(X_mask)
        for k in range(len(X_test)):
            tem=num_points
            for i in range(total):
                
                index=k*total+i
                distance = np.sqrt(  (y_pred[index][0]-y_test[k][0])**2 + (y_pred[index][1]-y_test[k][1])**2 + (y_pred[index][2]-y_test[k][2])**2  )
                if distance < 0.225:
                    tem=i/total*num_points
                    break
            success+=tem
        success/=len(X_test)
        y.append(success)
    print(x_snr,y)
    plt.plot(x_snr,y)
    plt.ylabel('#measurements')
    plt.xlabel('snr')
    plt.show()

draw_pro_snr()
#draw_meas_snr()















